{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import misaki\n",
    "import re\n",
    "from langdetect import detect\n",
    "from misaki import vi, zh, espeak\n",
    "espeak.EspeakWrapper.set_library('C:\\Program Files\\eSpeak NG\\libespeak-ng.dll')\n",
    "\n",
    "def g2p(text, g2p_dict):\n",
    "    phonemes, tokens = g2p_dict[\"main\"](text)\n",
    "    # Use a regex to extract all substrings enclosed in square brackets.\n",
    "    bracketed_texts = re.findall(r'\\[(.*?)\\]', phonemes)\n",
    "    # Iterate through each detected bracketed text.\n",
    "    for segment in bracketed_texts:\n",
    "        try:\n",
    "            # Detect language of the segment. Need to to manually because Espeak lang detection is not reliable.\n",
    "            detected_lang = detect(segment)\n",
    "        except Exception as e:\n",
    "            fallback = g2p_dict['fallback'](segment)[0]\n",
    "            phonemes = phonemes.replace(f\"[{segment}]\", fallback)\n",
    "            continue\n",
    "\n",
    "        if detected_lang.startswith(\"zh\"):\n",
    "            zh_phonemes, zh_tokens = g2p_dict['zh'](segment)\n",
    "            converted = zh_phonemes\n",
    "        elif detected_lang.startswith(\"zh\"):\n",
    "            #espeak fallback for languages\n",
    "            ja_phonemes = g2p_dict['ja'](segment)[0]\n",
    "            converted = ja_phonemes\n",
    "        else:\n",
    "            fallback = g2p_dict['fallback'](segment)[0]\n",
    "            converted = fallback\n",
    "        phonemes = phonemes.replace(f\"[{segment}]\", converted)\n",
    "    return phonemes\n",
    "\n",
    "main_g2p = vi.VIG2P()\n",
    "zh_g2p = zh.ZHG2P()\n",
    "ja_g2p = espeak.EspeakG2P(language='ja')\n",
    "fallback_vi = espeak.EspeakG2P(language='vi')\n",
    "g2p_dict = {\"main\":main_g2p, \"zh\":zh_g2p, \"ja\":ja_g2p, \"fallback\":fallback_vi}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hao hảo háo hào hạo a á â o ơ u ư e ê\n",
      "haw1 haw4 haw5 haw2 haw6 a1 a5 ɤ̆1 ɔ1 ɤ1 u1 ɯ1 ɛ1 e1\n",
      "hˈaːw hˈaː4w hˈaːɜw hˈaː2w hˈaː6w ˈaː ˈaːɜ ˈə ˈɔ ˈəː ˈu ˈy ˈɛ ˈe\n"
     ]
    }
   ],
   "source": [
    "#text = 'Hello 你好 xin chào にっぽん'\n",
    "text = 'hao hảo háo hào hạo a á â o ơ u ư e ê'\n",
    "phonemes = g2p(text, g2p_dict)\n",
    "\n",
    "espeak_vn = espeak.EspeakG2P(language='vi')\n",
    "\n",
    "print(text)\n",
    "print(phonemes)\n",
    "print(espeak_vn(text)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_pad = \"$\"\n",
    "_punctuation = ';:,.!?¡¿—…\"«»“” '\n",
    "_letters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "_letters_ipa = \"ɑɐɒæɓʙβɔɕçɗɖðʤəɘɚɛɜɝɞɟʄɡɠɢʛɦɧħɥʜɨɪʝɭɬɫɮʟɱɯɰŋɳɲɴøɵɸθœɶʘɹɺɾɻʀʁɽʂʃʈʧʉʊʋⱱʌɣɤʍχʎʏʑʐʒʔʡʕʢǀǁǂǃˈˌːˑʼʴʰʱʲʷˠˤ˞↓↑→↗↘'̩'ᵻ\"\n",
    "_extend = \"∫̆ăη͡123456\"\n",
    "\n",
    "# Export all symbols:\n",
    "symbols = [_pad] + list(_punctuation) + list(_letters) + list(_letters_ipa) + list(_extend)\n",
    "\n",
    "dicts = {}\n",
    "for i in range(len((symbols))):\n",
    "    dicts[symbols[i]] = i\n",
    "\n",
    "len(dicts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_syms = ['ɯəj', 'ɤ̆j', 'ʷiə', 'ɤ̆w', 'ɯəw', 'ʷet', 'iəw', 'uəj', 'ʷen', 'tʰw', 'ʷɤ̆', 'ʷiu', 'kwi', 'ŋ͡m', 'k͡p', 'cw', 'jw', 'uə', 'eə', 'bw', 'oj', 'ʷi', 'vw', 'ăw', 'ʈw', 'ʂw', 'aʊ', 'fw', 'ɛu', 'tʰ', 'tʃ', 'ɔɪ', 'xw', 'ʷɤ', 'ɤ̆', 'ŋw', 'ʊə', 'zi', 'ʷă', 'dw', 'eɪ', 'aɪ', 'ew', 'iə', 'ɣw', 'zw', 'ɯj', 'ʷɛ', 'ɯw', 'ɤj', 'ɔ:', 'əʊ', 'ʷa', 'mw', 'ɑ:', 'hw', 'ɔj', 'uj', 'lw', 'ɪə', 'ăj', 'u:', 'aw', 'ɛj', 'iw', 'aj', 'ɜ:', 'kw', 'nw', 't∫', 'ɲw', 'eo', 'sw', 'tw', 'ʐw', 'iɛ', 'ʷe', 'i:', 'ɯə', 'dʒ', 'ɲ', 'θ', 'ʌ', 'l', 'w', '1', 'ɪ', 'ɯ', 'd', '∫', 'p', 'ə', 'u', 'o', '3', 'ɣ', '!', 'ð', 'ʧ', '6', 'ʒ', 'ʐ', 'z', 'v', 'g', 'ă', 'æ', 'ɤ', '2', 'ʤ', 'i', '.', 'ɒ', 'b', 'h', 'n', 'ʂ', 'ɔ', 'ɛ', 'k', 'm', '5', ' ', 'c', 'j', 'x', 'ʈ', ',', '4', 'ʊ', 's', 'ŋ', 'a', 'ʃ', '?', 'r', ':', 'η', 'f', ';', 'e', 't', \"'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_char = []\n",
    "for char in \"\".join(vi_syms):\n",
    "    if char in dicts.keys():\n",
    "        continue\n",
    "    else:\n",
    "        print(char)\n",
    "        unk_char.append(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[165, 140, 179, 16, 165, 180, 16, 53, 182, 58]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"ʷɤ̆ ʷă k͡p\"\n",
    "\n",
    "[dicts[char] for char in test]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
