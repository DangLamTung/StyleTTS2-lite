{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\catto\\Desktop\\Code\\Project\\TTS\\StyleTTS2\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import yaml\n",
    "from munch import Munch\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from models import *\n",
    "from utils import *\n",
    "\n",
    "device = 'cpu'#'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\catto\\anaconda3\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "c:\\Users\\catto\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "#config = yaml.safe_load(open(\"Models/LibriTTS/config.yml\"))\n",
    "config = yaml.safe_load(open(\"Configs/config.yml\"))\n",
    "# ASR_path = config.get('ASR_path', False)\n",
    "# text_aligner = ASRCNN(\n",
    "#         input_dim = 80,\n",
    "#         hidden_dim = 256,\n",
    "#         n_token = 178,\n",
    "#         token_embedding_dim = 512,\n",
    "# )\n",
    "# asr_params = torch.load(ASR_path, map_location='cpu')\n",
    "# text_aligner.load_state_dict(asr_params['model'])\n",
    "\n",
    "model_params = recursive_munch(config['model_params'])\n",
    "#model = build_model(model_params, text_aligner = text_aligner, pitch_extractor = None)\n",
    "model = build_model(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder loaded\n",
      "predictor loaded\n",
      "text_encoder loaded\n",
      "predictor_encoder loaded\n",
      "style_encoder loaded\n",
      "text_aligner loaded\n",
      "pitch_extractor loaded\n",
      "mpd loaded\n",
      "msd loaded\n"
     ]
    }
   ],
   "source": [
    "keys_to_keep = {'predictor', 'decoder', 'text_encoder','predictor_encoder', 'style_encoder', 'text_aligner', 'pitch_extractor', 'mpd', 'msd'} #remove 'bert', 'bert_encoder'; not needed in inference 'text_aligner'\n",
    "#params_whole = torch.load(\"Models/LibriTTS/og.pth\", map_location='cpu')\n",
    "params_whole = torch.load(\"Models/Finetune_Removed/og_finetune.pth\", map_location='cpu')\n",
    "params = params_whole['net']\n",
    "params = {key: value for key, value in params.items() if key in keys_to_keep}\n",
    "\n",
    "for key in list(model.keys()):\n",
    "    if key not in keys_to_keep:\n",
    "        del model[key]\n",
    "\n",
    "for key in model:\n",
    "    if key in params:\n",
    "        print('%s loaded' % key)\n",
    "        try:\n",
    "            model[key].load_state_dict(params[key])\n",
    "        except:\n",
    "            from collections import OrderedDict\n",
    "            state_dict = params[key]\n",
    "            new_state_dict = OrderedDict()\n",
    "            for k, v in state_dict.items():\n",
    "                name = k[7:] # remove `module.`\n",
    "                new_state_dict[name] = v\n",
    "            # load params\n",
    "            model[key].load_state_dict(new_state_dict, strict=False)\n",
    "#             except:\n",
    "#                 _load(params[key], model[key])\n",
    "_ = [model[key].eval() for key in model]\n",
    "_ = [model[key].to(device) for key in model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_weight = [\n",
    "    model['text_encoder'].embedding,\n",
    "    model['text_aligner'].ctc_linear[2].linear_layer,\n",
    "    model['text_aligner'].asr_s2s.embedding,\n",
    "    model['text_aligner'].asr_s2s.project_to_n_symbols\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(178, 512) torch.Size([178, 512])\n",
      "Linear(in_features=256, out_features=178, bias=True) torch.Size([178, 256])\n",
      "Embedding(178, 512) torch.Size([178, 512])\n",
      "Linear(in_features=128, out_features=178, bias=True) torch.Size([178, 128])\n"
     ]
    }
   ],
   "source": [
    "for module in old_weight:\n",
    "    print(module, module.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_to = 189\n",
    "\n",
    "for i in range(len(old_weight)):\n",
    "    new_shape = (extend_to, old_weight[i].weight.shape[1])\n",
    "    new_weight = torch.randn(new_shape) * 0.01 #init mean=0, std=0.01\n",
    "    with torch.no_grad():\n",
    "        new_weight[:old_weight[i].weight.size(0), :] = old_weight[i].weight.detach().clone()\n",
    "    new_param = nn.Parameter(new_weight, requires_grad=True)\n",
    "\n",
    "    if isinstance(old_weight[i], nn.Embedding):\n",
    "        old_weight[i].num_embeddings = extend_to\n",
    "        \n",
    "    if isinstance(old_weight[i], nn.Linear):\n",
    "        old_weight[i].out_features = extend_to\n",
    "        #update bias\n",
    "        old_bias = old_weight[i].bias.detach()\n",
    "        old_dim = old_bias.shape[0]\n",
    "        new_bias = torch.zeros(extend_to)\n",
    "        new_bias[:old_dim] = old_bias.clone()\n",
    "        old_weight[i].bias.data = new_bias\n",
    "\n",
    "    old_weight[i].weight = new_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(189, 512) torch.Size([189, 512])\n",
      "Linear(in_features=256, out_features=189, bias=True) torch.Size([189, 256])\n",
      "Embedding(189, 512) torch.Size([189, 512])\n",
      "Linear(in_features=128, out_features=189, bias=True) torch.Size([189, 128])\n"
     ]
    }
   ],
   "source": [
    "for module in old_weight:\n",
    "    print(module, module.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./Models/Finetune_Extend\"\n",
    "#save_path_asr = \"./Utils/ASR\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "state = {\n",
    "    'net':  {key: model[key].state_dict() for key in model}, \n",
    "    'optimizer': params_whole['optimizer'],\n",
    "    'iters': params_whole['iters'],\n",
    "    'val_loss': params_whole['val_loss'],\n",
    "    'epoch': params_whole['epoch'],\n",
    "}\n",
    "save_path = osp.join(save_path, 'extended.pth')\n",
    "\n",
    "# state_asr = {\n",
    "#     'optimizer': asr_params['optimizer'],\n",
    "#     'scheduler': asr_params['scheduler'],\n",
    "#     'steps': asr_params['steps'],\n",
    "#     'epochs': asr_params['epochs'],\n",
    "#     'model': model['text_aligner'].state_dict(),\n",
    "# }\n",
    "# save_path_asr = osp.join(save_path_asr, 'extended_asr.pth')\n",
    "\n",
    "torch.save(state, save_path)  \n",
    "#torch.save(state_asr, save_path_asr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
